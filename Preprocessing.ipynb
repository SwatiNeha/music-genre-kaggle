{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*use_inf_as_na.*\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Combined_train.csv')\n",
    "df_test = pd.read_csv('testing-instances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the Time Signature column correctly for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time_signature(date_format):\n",
    "    #formats to correct time signatures\n",
    "    time_signature_correction = {\n",
    "        '04-Apr': 4/4,\n",
    "        '03-Apr': 3/4,\n",
    "        '01-Apr': 1/4,\n",
    "        '05-Apr': 5/4,\n",
    "        '0/4' : 0/4\n",
    "    }\n",
    "    if date_format in time_signature_correction:\n",
    "        return time_signature_correction[date_format]\n",
    "    else:\n",
    "        return date_format\n",
    "\n",
    "#For encoding time_signature column to correct format\n",
    "df['time_signature'] = pd.to_numeric(df['time_signature'].apply(encode_time_signature))\n",
    "df_test['time_signature'] = pd.to_numeric(df_test['time_signature'].apply(encode_time_signature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " instance_id             0\n",
      "artist_name             0\n",
      "track_name              0\n",
      "track_id                0\n",
      "popularity              0\n",
      "acousticness            0\n",
      "danceability            0\n",
      "duration_ms         10114\n",
      "energy                  0\n",
      "instrumentalness        0\n",
      "key                     0\n",
      "liveness                0\n",
      "loudness                0\n",
      "mode                    0\n",
      "speechiness             0\n",
      "tempo                7501\n",
      "time_signature          0\n",
      "valence                 0\n",
      "genre                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Converting tempo column to numeric\n",
    "df['tempo'] = pd.to_numeric(df['tempo'], errors='coerce')\n",
    "df['duration_ms'] = df['duration_ms'].replace(-1, np.nan)\n",
    "#df['artist_name'] = df['artist_name'].replace('empty_field', np.nan)\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new= df.copy()\n",
    "numeric_cols = df_new.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_new.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imputer = IterativeImputer()\n",
    "numeric_data_imputed = imputer.fit_transform(df_new[numeric_cols])\n",
    "numeric_data_imputed = pd.DataFrame(numeric_data_imputed, columns=numeric_cols)\n",
    "categorical_data = df_new[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values:\n",
      " instance_id         0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "valence             0\n",
      "artist_name         0\n",
      "track_name          0\n",
      "track_id            0\n",
      "key                 0\n",
      "mode                0\n",
      "genre               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_new_comp = pd.concat([numeric_data_imputed, categorical_data], axis=1)\n",
    "\n",
    "# Print the number of missing values in the new DataFrame\n",
    "print(\"The number of missing values:\\n\", df_new_comp.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " instance_id            0\n",
      "artist_name            0\n",
      "track_name             0\n",
      "track_id               0\n",
      "popularity             0\n",
      "acousticness           0\n",
      "danceability           0\n",
      "duration_ms         2515\n",
      "energy                 0\n",
      "instrumentalness       0\n",
      "key                    0\n",
      "liveness               0\n",
      "loudness               0\n",
      "mode                   0\n",
      "speechiness            0\n",
      "tempo               1874\n",
      "time_signature         0\n",
      "valence                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test['tempo'] = pd.to_numeric(df_test['tempo'], errors='coerce')\n",
    "df_test['duration_ms'] = df_test['duration_ms'].replace(-1, np.nan)\n",
    "missing_values = df_test.isnull().sum()\n",
    "\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_test.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_test.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values:\n",
      " instance_id         0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "valence             0\n",
      "artist_name         0\n",
      "track_name          0\n",
      "track_id            0\n",
      "key                 0\n",
      "mode                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "numeric_data_imputed = imputer.transform(df_test[numeric_cols])\n",
    "numeric_data_imputed = pd.DataFrame(numeric_data_imputed, columns=numeric_cols)\n",
    "categorical_data = df_test[categorical_cols]\n",
    "df_test_comp = pd.concat([numeric_data_imputed, categorical_data], axis=1)\n",
    "\n",
    "print(\"The number of missing values:\\n\", df_test_comp.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing Clean data in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_comp.to_csv('Cleaned_data.csv', index=False)\n",
    "df_test_comp.to_csv('Cleaned_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('Cleaned_data.csv')\n",
    "df_test = pd.read_csv('Cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering of Data from gained Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bimodal nature of Instrumentalness and Acousticness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "instrumentalness = df_new[['instrumentalness']].dropna()\n",
    "\n",
    "# Fit Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(instrumentalness)\n",
    "df_new['instrumentalness_mode'] = gmm.predict(instrumentalness)\n",
    "df_new['instrumentalness_low'] = df_new['instrumentalness'].where(df_new['instrumentalness_mode'] == 0, 0)\n",
    "df_new['instrumentalness_high'] = df_new['instrumentalness'].where(df_new['instrumentalness_mode'] == 1, 0)\n",
    "df_new.drop(columns=['instrumentalness'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrumentalness_test = df_test[['instrumentalness']].dropna()\n",
    "instrumentalness_mode_test = gmm.predict(instrumentalness_test)\n",
    "df_test['instrumentalness_mode'] = instrumentalness_mode_test\n",
    "df_test['instrumentalness_low'] = df_test['instrumentalness'].where(df_test['instrumentalness_mode'] == 0, 0)\n",
    "df_test['instrumentalness_high'] = df_test['instrumentalness'].where(df_test['instrumentalness_mode'] == 1, 0)\n",
    "\n",
    "# Drop the original feature if necessary\n",
    "df_test.drop(columns=['instrumentalness'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acousticness = df_new[['acousticness']].dropna()\n",
    "# Fit Gaussian Mixture Model for acousticness\n",
    "gmm_acousticness = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm_acousticness.fit(acousticness)\n",
    "\n",
    "# Predict and create new columns based on the mixture components\n",
    "df_new['acousticness_mode'] = gmm_acousticness.predict(acousticness)\n",
    "df_new['acousticness_low'] = df_new['acousticness'].where(df_new['acousticness_mode'] == 0, 0)\n",
    "df_new['acousticness_high'] = df_new['acousticness'].where(df_new['acousticness_mode'] == 1, 0)\n",
    "\n",
    "# Drop the original acousticness column if necessary\n",
    "df_new.drop(columns=['acousticness'], inplace=True)\n",
    "\n",
    "# Handle the acousticness column for test data\n",
    "acousticness_test = df_test[['acousticness']].dropna()\n",
    "acousticness_mode_test = gmm_acousticness.predict(acousticness_test)\n",
    "\n",
    "df_test['acousticness_mode'] = acousticness_mode_test\n",
    "df_test['acousticness_low'] = df_test['acousticness'].where(df_test['acousticness_mode'] == 0, 0)\n",
    "df_test['acousticness_high'] = df_test['acousticness'].where(df_test['acousticness_mode'] == 1, 0)\n",
    "\n",
    "# Drop the original acousticness column in the test set if necessary\n",
    "df_test.drop(columns=['acousticness'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Initialize PowerTransformer for Box-Cox\n",
    "pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "\n",
    "# Shift features in the training data\n",
    "df_new['liveness_shifted'] = df_new['liveness'] + (1 - df_new['liveness'].min() if df_new['liveness'].min() <= 0 else 0)\n",
    "df_new['loudness_shifted'] = df_new['loudness'] + (1 - df_new['loudness'].min() if df_new['loudness'].min() <= 0 else 0)\n",
    "df_new['speechiness_shifted'] = df_new['speechiness'] + (1 - df_new['speechiness'].min() if df_new['speechiness'].min() <= 0 else 0)\n",
    "\n",
    "pt.fit(df_new[['liveness_shifted', 'loudness_shifted', 'speechiness_shifted']])\n",
    "\n",
    "# Apply transformation to training data\n",
    "df_new[['bc_liveness', 'bc_loudness', 'bc_speechiness']] = pt.transform(df_new[['liveness_shifted', 'loudness_shifted', 'speechiness_shifted']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['liveness_shifted'] = df_test['liveness'] + (1 - df_new['liveness'].min() if df_test['liveness'].min() <= 0 else 0)\n",
    "df_test['loudness_shifted'] = df_test['loudness'] + (1 - df_new['loudness'].min() if df_test['loudness'].min() <= 0 else 0)\n",
    "df_test['speechiness_shifted'] = df_test['speechiness'] + (1 - df_new['speechiness'].min() if df_test['speechiness'].min() <= 0 else 0)\n",
    "\n",
    "df_test[['bc_liveness', 'bc_loudness', 'bc_speechiness']] = pt.transform(df_test[['liveness_shifted', 'loudness_shifted', 'speechiness_shifted']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(columns=['liveness_shifted', 'loudness_shifted', 'speechiness_shifted','liveness','loudness','speechiness'], inplace=True)\n",
    "df_test.drop(columns=['liveness_shifted', 'loudness_shifted', 'speechiness_shifted','liveness','loudness','speechiness'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing Final Transformed Data into Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('Cleaned_final_data.csv', index=False)\n",
    "df_test.to_csv('Cleaned_final_test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
